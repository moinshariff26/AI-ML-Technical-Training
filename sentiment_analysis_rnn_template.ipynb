{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b62e53a",
   "metadata": {},
   "source": [
    "# Understanding RNNs and LSTMs for Sentiment Analysis - Template\n",
    "\n",
    "## What is a Recurrent Neural Network (RNN)?\n",
    "RNNs are neural networks designed to work with sequential data. Unlike traditional neural networks, they maintain an internal memory (hidden state) that allows them to remember information from previous inputs.\n",
    "\n",
    "![RNN Basic Structure](https://www.mdpi.com/information/information-15-00517/article_deploy/html/images/information-15-00517-g001-550.jpg)\n",
    "\n",
    "### How RNNs Process Text:\n",
    "1. Words are converted to numbers (embeddings)\n",
    "2. Each word is processed sequentially\n",
    "3. Hidden state is updated at each step\n",
    "4. Final output depends on all previous inputs\n",
    "\n",
    "## Long Short-Term Memory (LSTM)\n",
    "LSTMs are an advanced form of RNN that solve the \"vanishing gradient\" problem, allowing them to remember long-term dependencies.\n",
    "\n",
    "![LSTM Cell Structure](https://miro.medium.com/v2/resize:fit:1156/1*laH0_xXEkFE0lKJu54gkFQ.png)\n",
    "\n",
    "![LSTM](https://databasecamp.de/wp-content/uploads/lstm-architecture-1024x709.png)\n",
    "\n",
    "### Key Components of LSTM:\n",
    "1. **Forget Gate**: Decides what information to discard\n",
    "2. **Input Gate**: Decides what new information to store\n",
    "3. **Cell State**: Long-term memory component\n",
    "4. **Output Gate**: Decides what parts of cell state to output\n",
    "\n",
    "## Our Task: Sentiment Analysis\n",
    "We'll use an LSTM network to analyze movie reviews and classify them as positive or negative.\n",
    "\n",
    "![Sentiment Analysis Process](https://miro.medium.com/max/700/1*SICYykT7ybua1gVJDNlajw.png)\n",
    "\n",
    "### Process Flow:\n",
    "1. Text → Numbers (Embedding)\n",
    "2. LSTM processes word sequence\n",
    "3. Dense layers interpret LSTM output\n",
    "4. Final prediction (0 = Negative, 1 = Positive)# Understanding RNNs and LSTMs for Sentiment Analysis\n",
    "\n",
    "## What is a Recurrent Neural Network (RNN)?\n",
    "RNNs are neural networks designed to work with sequential data. Unlike traditional neural networks, they maintain an internal memory (hidden state) that allows them to remember information from previous inputs.\n",
    "\n",
    "![RNN Basic Structure](https://www.mdpi.com/information/information-15-00517/article_deploy/html/images/information-15-00517-g001-550.jpg)\n",
    "\n",
    "### How RNNs Process Text:\n",
    "1. Words are converted to numbers (embeddings)\n",
    "2. Each word is processed sequentially\n",
    "3. Hidden state is updated at each step\n",
    "4. Final output depends on all previous inputs\n",
    "\n",
    "## Long Short-Term Memory (LSTM)\n",
    "LSTMs are an advanced form of RNN that solve the \"vanishing gradient\" problem, allowing them to remember long-term dependencies.\n",
    "\n",
    "![LSTM Cell Structure](https://miro.medium.com/v2/resize:fit:1156/1*laH0_xXEkFE0lKJu54gkFQ.png)\n",
    "\n",
    "![LSTM](https://databasecamp.de/wp-content/uploads/lstm-architecture-1024x709.png)\n",
    "\n",
    "### Key Components of LSTM:\n",
    "1. **Forget Gate**: Decides what information to discard\n",
    "2. **Input Gate**: Decides what new information to store\n",
    "3. **Cell State**: Long-term memory component\n",
    "4. **Output Gate**: Decides what parts of cell state to output\n",
    "\n",
    "## Our Task: Sentiment Analysis\n",
    "We'll use an LSTM network to analyze movie reviews and classify them as positive or negative.\n",
    "\n",
    "![Sentiment Analysis Process](https://miro.medium.com/max/700/1*SICYykT7ybua1gVJDNlajw.png)\n",
    "\n",
    "### Process Flow:\n",
    "1. Text → Numbers (Embedding)\n",
    "2. LSTM processes word sequence\n",
    "3. Dense layers interpret LSTM output\n",
    "4. Final prediction (0 = Negative, 1 = Positive)\n",
    "\n",
    "Follow the TODOs in each section to complete the implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c594b",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using RNN (LSTM) - Template\n",
    "\n",
    "This notebook provides a template for building a Recurrent Neural Network (LSTM) for sentiment analysis using the IMDB movie reviews dataset.\n",
    "\n",
    "### Learning Objectives:\n",
    "1. Understand RNN/LSTM architecture\n",
    "2. Learn text preprocessing for deep learning\n",
    "3. Build and train an LSTM model\n",
    "4. Evaluate model performance\n",
    "5. Make predictions on new text\n",
    "\n",
    "### Dataset:\n",
    "We'll use the IMDB dataset which contains 50,000 movie reviews labeled as positive (1) or negative (0).\n",
    "\n",
    "### Instructions:\n",
    "Follow the TODOs in each section to complete the implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a600491b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Setup\n",
    "\n",
    "TODO: Import the necessary libraries:\n",
    "- TensorFlow and Keras\n",
    "- NumPy\n",
    "- Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f47967",
   "metadata": {},
   "source": [
    "### Text Preprocessing Steps\n",
    "\n",
    "Before we can use text data in our LSTM, we need to:\n",
    "\n",
    "1. **Convert Words to Numbers**\n",
    "   ```python\n",
    "   # Example:\n",
    "   \"Great movie!\" → [143, 256, 1]  # Each number represents a word\n",
    "   ```\n",
    "\n",
    "2. **Make Sequences Same Length**\n",
    "   ```python\n",
    "   # Example:\n",
    "   [143, 256, 1] → [143, 256, 1, 0, 0]  # Padding with zeros\n",
    "   ```\n",
    "\n",
    "3. **Create Word Embeddings**\n",
    "   ```python\n",
    "   # Example:\n",
    "   143 → [0.2, -0.5, 0.1, ...]  # Convert to dense vector\n",
    "   ```\n",
    "\n",
    "![Text Processing](https://raw.githubusercontent.com/dair-ai/ml-visuals/master/images/text-preprocessing.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93490f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import required libraries\n",
    "# Hint: You need tensorflow, numpy, and matplotlib\n",
    "\n",
    "# Print TensorFlow version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7246c8dc",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess the IMDB Dataset\n",
    "\n",
    "TODO:\n",
    "1. Set vocabulary size and maximum sequence length\n",
    "2. Load the IMDB dataset\n",
    "3. Pad sequences to ensure uniform length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71aa683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set parameters\n",
    "# vocab_size = ...  # Only keep top 10k words\n",
    "# max_length = ...  # Maximum length of each review\n",
    "# trunc_type = ...  # Where to truncate\n",
    "# padding_type = ... # Where to add padding\n",
    "\n",
    "# TODO: Load the IMDB dataset\n",
    "# Hint: Use imdb.load_data()\n",
    "\n",
    "# TODO: Pad the sequences\n",
    "# Hint: Use pad_sequences()\n",
    "\n",
    "# Print shapes of training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d0cba",
   "metadata": {},
   "source": [
    "## 3. Build the LSTM Model\n",
    "\n",
    "TODO: Create a Sequential model with:\n",
    "1. Embedding layer\n",
    "2. One or more LSTM layers\n",
    "3. Dense layers for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160be7d3",
   "metadata": {},
   "source": [
    "### LSTM Model Architecture\n",
    "\n",
    "You'll build a model with these layers:\n",
    "\n",
    "1. **Embedding Layer**\n",
    "   ```python\n",
    "   Embedding(vocab_size, embedding_dim, input_length=max_length)\n",
    "   ```\n",
    "   ![Word Embedding](https://arize.com/wp-content/uploads/2022/06/blog-king-queen-embeddings.jpg)\n",
    "\n",
    "2. **LSTM Layers**\n",
    "   ```python\n",
    "   LSTM(units=64, return_sequences=True)  # First LSTM\n",
    "   LSTM(units=32)                         # Second LSTM\n",
    "   ```\n",
    "  ![Stacked LSTM](https://www.researchgate.net/publication/328819708/figure/fig4/AS:845838377046027@1578674992640/Simple-LSTM-Vs-Stacked-LSTM.png)\n",
    "3. **Dense Layers**\n",
    "   ```python\n",
    "   Dense(16, activation='relu')     # Hidden layer\n",
    "   Dense(1, activation='sigmoid')   # Output layer\n",
    "   ```\n",
    "   ![Dense Layers](https://i.sstatic.net/dpp2W.png)\n",
    "\n",
    "Complete the TODOs to implement this architecture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b3502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set embedding dimension\n",
    "# embedding_dim = ...\n",
    "\n",
    "# TODO: Build the model\n",
    "# model = Sequential([\n",
    "#     # Add Embedding layer\n",
    "#     # Add LSTM layer(s)\n",
    "#     # Add Dense layer(s)\n",
    "# ])\n",
    "\n",
    "# TODO: Compile the model\n",
    "# Hint: Use binary_crossentropy loss and adam optimizer\n",
    "\n",
    "# Print model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1100291",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "TODO:\n",
    "1. Set up early stopping callback\n",
    "2. Train the model with validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd9c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define callbacks\n",
    "# Hint: Use EarlyStopping\n",
    "\n",
    "# TODO: Train the model\n",
    "# Hint: Use model.fit with validation_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597531d",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Model\n",
    "\n",
    "TODO:\n",
    "1. Plot training history\n",
    "2. Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c76feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training history\n",
    "# Hint: Use plt.plot() for accuracy and loss\n",
    "\n",
    "# TODO: Evaluate on test set\n",
    "# Hint: Use model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57491a",
   "metadata": {},
   "source": [
    "## 6. Make Predictions\n",
    "\n",
    "TODO:\n",
    "1. Create a function to encode new text\n",
    "2. Test the model with sample reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a832aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the word index\n",
    "# Hint: Use imdb.get_word_index()\n",
    "\n",
    "# TODO: Create a function to encode text\n",
    "# def encode_text(text):\n",
    "#     # Your code here\n",
    "#     pass\n",
    "\n",
    "# TODO: Test with sample reviews\n",
    "# sample_reviews = [\n",
    "#     \"This movie was fantastic! I really loved it.\",\n",
    "#     \"I hated this movie. It was terrible.\"\n",
    "# ]\n",
    "\n",
    "# TODO: Make predictions\n",
    "# Hint: Use model.predict()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
